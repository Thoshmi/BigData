{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zn8KIzWR7llI",
        "outputId": "1fa439ca-184b-4c14-f590-a9d02a4857ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best K value: 19\n",
            "Mean Accuracy: 0.6602\n",
            "Standard Deviation: 0.0459\n",
            "<IPython.core.display.Markdown object>\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from IPython.display import Markdown\n",
        "import numpy as np\n",
        "\n",
        "# Data loading and preprocessing\n",
        "data_train = pd.read_csv(\"train.csv\")\n",
        "data_test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Feature selection\n",
        "features = [\"Age\", \"Fare\"]\n",
        "\n",
        "# Imputation\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "data_train[features] = imputer.fit_transform(data_train[features])\n",
        "data_test[features] = imputer.transform(data_test[features])\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(data_train[features])\n",
        "data_train[features] = scaler.transform(data_train[features])\n",
        "data_test[features] = scaler.transform(data_test[features])\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, _ = train_test_split(\n",
        "    data_train[features], data_train[\"Survived\"], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# KNN Model and Cross-Validation\n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "model = KNeighborsClassifier()\n",
        "\n",
        "# Option 1: Filter results after adjusting k values\n",
        "k_range = range(1, 21)\n",
        "accuracies = []\n",
        "adjusted_k_values = []\n",
        "for train_indices, test_indices in kfold.split(X_train):\n",
        "    X_train_fold, X_test_fold = X_train.iloc[train_indices], X_train.iloc[test_indices]\n",
        "    y_train_fold, y_test_fold = y_train.iloc[train_indices], y_train.iloc[test_indices]\n",
        "\n",
        "    n_samples = X_train_fold.shape[0]\n",
        "    adjusted_k = min(k, n_samples)\n",
        "    if adjusted_k in k_range:\n",
        "        model.set_params(n_neighbors=adjusted_k)\n",
        "        model.fit(X_train_fold, y_train_fold)\n",
        "        predictions = model.predict(X_test_fold)\n",
        "        accuracies.append(accuracy_score(y_test_fold, predictions))\n",
        "        adjusted_k_values.append(adjusted_k)\n",
        "\n",
        "best_k = adjusted_k_values[np.argmax(accuracies)]\n",
        "\n",
        "# Option 2: Use a dictionary\n",
        "# k_accuracies = {}\n",
        "# for train_indices, test_indices in kfold.split(X_train):\n",
        "#     X_train_fold, X_test_fold = X_train.iloc[train_indices], X_train.iloc[test_indices]\n",
        "#     y_train_fold, y_test_fold = y_train.iloc[train_indices], y_train.iloc[test_indices]\n",
        "#\n",
        "#     n_samples = X_train_fold.shape[0]\n",
        "#     adjusted_k = min(k, n_samples)\n",
        "#     k_accuracies[adjusted_k] = accuracy_score(y_test_fold, model.fit(X_train_fold, y_train_fold).predict(X_test_fold))\n",
        "#\n",
        "# best_k = max(k_accuracies, key=k_accuracies.get)\n",
        "\n",
        "# Report results\n",
        "print(f\"Best K value: {best_k}\")\n",
        "print(f\"Mean Accuracy: {np.mean(accuracies):.4f}\")\n",
        "print(f\"Standard Deviation: {np.std(accuracies):.4f}\")\n",
        "\n",
        "# Confusion matrix\n",
        "confusion_matrix(y_train, model.fit(X_train, y_train).predict(X_train))\n",
        "\n",
        "# Model accuracy explanation\n",
        "model_explanation = Markdown(\n",
        "    \"\"\"\n",
        "The KNN model achieved a mean accuracy of [mean_accuracy] with a standard deviation of [std_deviation] across 5 folds, suggesting good generalizability. However, further analysis like analyzing the confusion matrix and tuning hyperparameters is recommended for a complete picture.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "print(model_explanation)\n"
      ]
    }
  ]
}